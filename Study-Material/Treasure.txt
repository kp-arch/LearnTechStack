
=========Java Class Loader=========================
Class Loaders
https://www.youtube.com/watch?v=Dpuy8WUBq9w

Class loaders are responsible for loading Java classes dynamically to the JVM (Java Virtual Machine) during runtime. They’re also part of the JRE (Java Runtime Environment). Therefore, the JVM doesn’t need to know about the underlying files or file systems in order to run Java programs thanks to class loaders.


JVM -----> Class Loader sub systems (it deligate call to below
			1. Bootstrap class Load - find and load calss es in %JAVA_HOME%/jre/lib/rt.jar
			2. Extension class Load - find and load calss es in %JAVA_HOME%/jre/lib/ext/*.jar
			4. Application class Load - All the custom class and classes available in -classpath or -cp

Linking Phase - Once class is loaded it start linking by following steps
1. Verification - 
				Binary represantation is correct or not, 
				.class file is generated by valid compiler or not
				.class file is formatted peroperly or not
				Fail with VerifyException if anything is incorrect
				
2. Preparation
				Memory is allocated for Class variables
				Default values are assigned (assume int i is static) then i=0 
				
3. Rosulation (Optional)
				Replace symbolic references with actual reference---
				Fail with java.lang.NoClassDefFoundError if anything is incorrect

Initilization phases
				All static variable are assign with value (assume int i is static) then i=5 . this is reason static block, executed before running the code
				Static blocks will be executed from top to buttom
				
				Momory Area, it further divided into https://www.youtube.com/watch?v=CDijVBqEeJ8&t=339s
				
				Method Area 		- (onely one method area per JVM)is also called Metaspace after java 8 and Peranenet Gen before it
										It store class level information like class name, method and variable
										static variable
								
				Heap Area			- (onely one method area per JVM) It stores objects, insstance variable
				Stack Area			-	It store local variables, current running method
				PC Registers		-	it stores current execution instruction, Each thread has separate PC Registers.
				Native Method stack -	Each thread has separate Native stack is created., it is separate from java stack to handle native (non java code).

https://www.youtube.com/watch?v=Dpuy8WUBq9w - pending				

========SpringBoot=================================

SpringBoot makes it easy to create application, the earier sprint was content a lot of configuration and need to configure separately.


https://www.youtube.com/watch?v=1993zSY5UBI&list=PLA3GkZPtsafacdBLdd3p1DyRd5FGfr3Ue
<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-web</artifactId>
		</dependency>


@SpringBootApplication - It contents a many pre-configured featues including automatic compoent scanning, embedded server configuration etc, it include the annotations (@configuration, @EnableAutoConfiguration, @componentScan- the base package will be package where @SpringBootApplication declared.

@RestController
@RequestMapping("/users")
public class Application {
@PostMapping(path = "/profiles/brokers",
      consumes = MediaType.APPLICATION_JSON_VALUE,
      produces = MediaType.APPLICATION_JSON_VALUE)
  public ResponseEntity<BrokerRegistrationResponse> registerBroker(){}
  
  
    public static void main(String[] args) {
    SpringApplication.run(Application.class, args); //it will start and auto configure in embaded  tomcat server.
  }
}

public class JwtAuthenticationFilter extends OncePerRequestFilter {
@Override
  protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response,
      FilterChain filterChain){}
}

----------Spring security-
<dependency>
			<groupId>org.springframework.boot</groupId>
			<artifactId>spring-boot-starter-security</artifactId>
		</dependency>
@Configuration
@EnableWebSecurity
public class SecurityConfig  extedns WebSecurityCongigureAdapter{

@Bean
  public void configure(HttpSecurity http){
   http
        .authorizeRequests()
		.anyMatchers(HttpMethod.DELETE,  "/brokers/cases")
        .hasAnyAuthority(Role.BROKER.getValue(), Role.RESTRICTED_BROKER.getValue())
		.and()
		.formLogin
}
=================Bitwise operator==================
Bitwise operators work on binary digits or bits of input values. We can apply these to the integer types –  byte, short, int ,long

Operations
1. 	and 				&
2. 	or					|
3. 	xor					^
4. 	not					~
5.	left shift			<<
6.	right shift			>>
5. 	unsignedRightShift	>>>

First, the operands are converted to their binary representation
Next, the operator is applied to each binary number and the result is calculated
Finally, the result is converted back to its decimal representation

int result = 6 | 5;
0110
0101
-----
0111

Finally, the result 0111 will be converted back to decimal which is equal to 7:


--------Stream, Lambda, predicate-------

Lamda is a functional programming, having no access modifier, no return type and no name.
i.e it is an anonomous implementation of functional interface.

https://www.youtube.com/watch?v=E10Q6-nWO9g

1. without terminal operation the evaluation of stream is not performed
(Terminal operations do all the work, Since intermediate operations are lazy, it’s up to the terminal operation to do everything.
	a.	Perform all the intermediate operations as efficiently as possible. Ideally, just going 
	through the original data once.
	b. Work out the result of the operation, which is defined by the terminal operation itself. 
	For example, this could be a list of values, a single value, or a boolean (true/false).
	c.	Return the result.
2. We cann't resue stream object  once the stream is closed i.e terminal operation is executed, we will get runtime execption - IllegalStateException

terminal operation on stream are:
collect, forEach, reduce(Integer::sum), count, anyMatch, allMatch, nonMatch, findFirst, findAny, toArray, min, Max


-----method referece & constructor reference---

students.forEach(x -> System.out.println(x));
students.forEach(System.out::println) - it take each student and print it.

List<MobilePhone> mobilePhones = names.stream().map(MobilePhone::new).collect(Collector.toList());


------Some important functional interface method-------

Predicate 		- 	boolean test(T t);
BiPredicate		-	boolean test(T t, U u);

Function 		- 	R apply(T t);
BiFunction		-	R apply(T t, U u);

Consumer		- 	void accept(T t);
BiConsumer		-	void accept(T t, U u);

Supplier		-	T get();

Comparator		-	int compare(T o1, T o2);
-------Some import Stream API-------------
Stream<T> filter(Predicate<? super T> predicate);

<R> Stream<R> map(Function<? super T, ? extends R> mapper);
eg - stringList.stream().map(x -> x.toUpperCase()).toList(); //it take Function to peforform the desire result

Stream<T> sorted(Comparator<? super T> comparator);
eg-stringList.stream().sorted((o1, o2) -> o1.length() - o2.length()).toList();


-utility method i.e terminal operation
public static<T> Stream<T> generate(Supplier<? extends T> s)
eg - Stream.generate(() -> "hello").limit(10).toList(); // Generate List of hello with size 10

public static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f) 
Stream.iterate(0, x -> x + 1).limit(10).toList(); // Generate List of sequanital number with size 10
note - public interface UnaryOperator<T> extends Function<T, T>


Optional<T> reduce(BinaryOperator<T> accumulator);
integerList.stream().reduce((a, b) -> a + b).ifPresent(x -> System.out.println(x));
note-public interface BinaryOperator<T> extends BiFunction<T,T,T> 

boolean anyMatch(Predicate<? super T> predicate);
integerList.stream().anyMatch(x -> x > 5); //if any lement is greater than 5 return true

boolean allMatch(Predicate<? super T> predicate);
boolean noneMatch(Predicate<? super T> predicate);

Optional<T> findFirst();
integerList.stream().findFirst().ifPresent(x -> System.out.println(x)); // return first any from list
integerList.stream().findAny().ifPresent(x -> System.out.println(x));
findFirst return the first elements of the stream but findAny is free to select any element in the stream.

<R> Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper);
List<List<String>> sublist = Arrays.asList(Arrays.asList("apple", "banana"), Arrays.asList("orange", "mango"), Arrays.asList("lime", "papaya"));
        sublist.stream().flatMap(x -> x.stream()) //return a single list stream of all elements of sublist
eg -sublist.stream().flatMap(x -> x.stream()).map(x -> x.toUpperCase()).toList()		
	result - [APPLE, BANANA, ORANGE, MANGO, LIME, PAPAYA]
	

public static Collector<CharSequence, ?, String> joining()
Returns:a Collector that concatenates the input elements into a String, in encounter order
eg sublist.stream().flatMap(x -> x.stream()).map(x -> x.toUpperCase()).collect(Collectors.joining("-"))
APPLE-BANANA-ORANGE-MANGO-LIME-PAPAYA

List<String> stringList = Arrays.asList("apple", "banana","orange", "mango","lime", "papaya");
Collectors.counting()
result: 6
Collectors.grouping(x->x.length) //group by lengh of list
result: {4=[lime], 5=[apple, mango], 6=[banana, orange, papaya]}

stringList.stream().collect(Collectors.groupingBy(x -> x.length(), Collectors.joining("-")))) // can group as well as can use other collector as 2nd parameter eg- joining
result{4=lime, 5=apple-mango, 6=banana-orange-papaya}

ParallelStream - is used to workd parally by many threads
integerList.parallelStream().map(x -> x * x).toList();
note - parallelStream is executed by many threads hence the resultent list content value in not order way. Hence we use sequanital method to get just result in order however it will executed by many threads.
eg - integerList.parallelStream().map(x -> x * x).sequanital().toList();


partitions elements into two groups (true and false) based on predicate
Map<Boolean, String> collect = stringList.stream()
        .collect(Collectors.partitioningBy(x -> x.length() > 5, Collectors.joining("-")));
{false=apple-mango-lime, true=banana-orange-papaya}

List<List<String>> sublist = Arrays.asList(Arrays.asList("apple", "banana"), Arrays.asList("orange", "mango"), Arrays.asList("lime", "papaya"),Arrays.asList("apple", "banana"));
   Map<String, Integer> collect1 = sublist.stream().flatMap(x -> x.stream())
        .collect(Collectors.toMap(k -> k, v -> 1, (x, y) -> x + y));
    System.out.println(collect1);
result	: {papaya=1, orange=1, banana=2, apple=2, lime=1, mango=1}

IntSummaryStatistics intSummary = integerList.stream().collect(Collectors.summarizingInt(x -> x));
    System.out.println("Max: " + intSummary.getMax());
    System.out.println("Min: " + intSummary.getMin());
    System.out.println("Sum: " + intSummary.getSum());
    System.out.println("Average: " + intSummary.getAverage());
    System.out.println("Count: " + intSummary.getCount());


------
In most places streams are used today), using serial 
streams is almost definitely going to be faster. Yes, you read 
that correctly: for most ordinary use cases, you do not
want to go parallel.
Parallel streams can improve performance when:
• The input collection is BIG (think hundreds of 
thousands of elements at least)
• The stream pipeline is performing complicated, longrunning operations
• The decomposition (splitting) of the data/operations 
and merging of the results are not too costly
========================================================
Default method in interface

https://www.youtube.com/watch?v=8TAp5rxQy4s
if in two interface we have same default method and
a class implements both then there is ambiguty i.e compile time error
to remove ambiguty the class uses
InterfaceName.super.defaultMethodname();

it is also called diamond problem.

why we use static method if default method present in interface
==================
Executor is framework that help to manage the thread without writing much code

https://www.youtube.com/watch?v=Dma_NmOrp1c
https://www.youtube.com/watch?v=ip68xxgffC8&t=2200s

https://www.baeldung.com/java-rejectedexecutionhandler
 public static void main(String[] args) {
    ThreadPoolExecutor tf =
        new ThreadPoolExecutor(5, 15, 60, TimeUnit.SECONDS, new LinkedBlockingQueue<>(5),
            new ThreadPoolExecutor.AbortPolicy());

    for (int i = 0; i < 500; i++) {
      Callable<String> task = () -> {
        String name = Thread.currentThread().getName();
        System.out.println(name);
        return name;
      };
      Future<String> future = tf.submit(task);
    }
    tf.shutdown();
  }
  
  remember Future are special type of variable that expect to get the value once the execution of thread is complete, 
  if we get the value i.e future.get() then the executation of current thread will be block till the execution of submitted thread is finish, so use it wisely.
  
  java.util.concurrent.RejectedExecutionException
  
 ----
  
  1.Custum i.e ThreadPoolExecutor
  ArrayBlockingQueue	
  Bounded queue to store the tasks, if queue gets full, new thread is created (as long as count is less than max PoolSize, corePoolSize-is initial pool size)
  
  2.FixedThreadPoolExecutor
  LinkedBlockingQueue
  Threads are limite, thus unbounded queue to store all tasks
  
  3.Single ThreadPoolExecutor
  LinkedBlockingQueue 
  Threads are limite, thus unbounded queue to store all tasks
  
  4.CachedThreadPoolExecutor
  SynchroniousQueue  	
  Threads are unbounded, thus no need to store the task, Synchronous queue is a queue with single slot.
  
  5.ScheduledThreadPoolExecutor
  DelayedWorkQueue		
  Special Queue that deals with schedules/time-delay
  a.	// Scheduling the task which will execute after 5 seconds 
		threadPool.schedule(task, 5, TimeUnit.SECONDS); 
  b.	// Scheduling the task which will execute after 2 seconds and then repeats periodically with a period of 8 seconds 
		threadPool.scheduleAtFixedRate(task, 2, 8,TimeUnit.SECONDS); 
  c.	//Scheduling the task which will execute after 5 seconds and then there will be a delay of 5 seconds between the completion 
		threadPool.scheduleWithFixedDelay(task, 5, 5,TimeUnit.SECONDS); 
		
		
---------------CountdownLatch------------
CountDownLatch in Java is an important class that ensures one or more threads are in the queue for other threads to complete their set of operations.

CountDownLatch countDownLatch = new CountDownLatch(3);
    ExecutorService executorService = Executors.newFixedThreadPool(3);
    for (int i = 0; i < 3; i++) {
      executorService.execute(() -> {
        System.out.println(Thread.currentThread().getName() + " executed");
        countDownLatch.countDown();
      });
    }
    try {
      System.out.println("Waiting for all tasks to execute");
      countDownLatch.await();
      System.out.println("All tasks executed");
    } catch (InterruptedException e) {
      e.printStackTrace();
    }
    executorService.shutdown();
    System.out.println("Main method executed successfully");
  }	
  
----------Lock----------
Explicit Locks: Explicit locks are locks that are explicitly acquired and released by the programmer using classes like ReentrantLock and ReadWriteLock from the java.util.concurrent.locks package.
Intrinsic Locks: Intrinsic locks (also known as synchronized locks) are the default lock mechanism in Java, provided by the synchronized keyword. These are automatically managed by the JVM.

2. Type of Lock
Explicit Locks: These are manually controlled by the developer using specific lock objects (e.g., ReentrantLock, ReadWriteLock).
	ReentrantLock: Provides exclusive access to a resource. Only one thread can acquire the lock at any given time.
	ReadWriteLock: Has two types of locks:
		Read Lock: Multiple threads can acquire the read lock simultaneously, as long as no thread holds the write lock.
		Write Lock: Only one thread can acquire the write lock, and no other threads (whether they are readers or writers) can acquire the lock until the write lock is released.
Intrinsic Locks: These are implicitly controlled by the JVM and are associated with every object in Java.

3. Lock Control
Explicit Locks: Explicit locks provide more control over the lock acquisition and release. You can try to acquire the lock without blocking (e.g., using tryLock()), interrupt a thread waiting for a lock (lockInterruptibly()), and also check the lock status.
Intrinsic Locks: Intrinsic locks are simpler but less flexible. You cannot check if a thread holds the lock, nor can you try to acquire the lock without blocking unless you use a synchronized block with a wait() condition.

5. Lock Acquisition
Explicit Locks: Locks are manually acquired using methods like lock() and released using unlock(). The programmer must ensure that the lock is released (using finally block).
Intrinsic Locks: Locks are automatically acquired when entering a synchronized block or method and automatically released when exiting the block or method.  
=======================================================
Java Records
Introduced in Java 14, records are a special kind of class that is designed to be a simple, immutable data carrier.
Key Features of Records:

Accessors (getter methods) are generated by the compiler and cannot have their names or return types changed.
Overriding accessors should be done with caution.
The compiler generates a canonical constructor.
Records do not support inheritance.


https://medium.com/@mak0024/a-comprehensive-guide-to-java-records-2e8edcbd9c75#:~:text=A%20record%20automatically%20gets%20field,within%20methods%20or%20inner%20classes.




Lombok is an annotation-based Java library that allows you to reduce boilerplate code. Lombok offers various annotations aimed at replacing Java code that is well known for being boilerplate,
Even Lombok annotations @Data and @Value annotations have provided similar functionality for a long time, albeit with a little more lines:


https://medium.com/@alxkm/java-record-comparison-lombok-data-fb045895947d


Performance:

Records: Potentially better performance due to optimizations in the JVM for records.
Lombok @Data: May have some overhead due to runtime annotation processing.

Use Java Records if you are using Java 16 or later and need a simple, immutable data carrier with a fixed set of fields.
Use Lombok @Data if you need the flexibility of standard Java classes, possibly need mutable fields, or are using a version of Java earlier than 16.


An enum is for declaring at compile time a limited set of named instances. Each of the enum objects is instantiated when the enum class loads. At runtime, we cannot instantiate any more objects of that class (well, maybe with extreme reflection/introspection code, but I’ll ignore that).

A record in Java is not automatically instantiated. Your code instantiated as many objects of that class as you want, by calling new. So not at all the same.
=================================================================================================================
Sealed classes in Java 17 offer a powerful mechanism for controlling inheritance hierarchies and improving code maintainability for classes and interfaces.
sealed classes promote better encapsulation and maintainability of your code

public sealed class Shape permits Circle, Square, Triangle {
    // Class members and methods
}
In this example, the Shape class is declared as sealed, and it permits Circle, Square, and Triangle classes to extend it.

public sealed interface Service permits Car, Truck {
}

public abstract sealed class Vehicle permits Car, Truck {
}

A permitted subclass may also be declared sealed. However, if we declare it non-sealed, then it’s open for extension:
public non-sealed class Car extends Vehicle implements Service {
}


A sealed class imposes three important constraints on its permitted subclasses:

All permitted subclasses must belong to the same module as the sealed class.
Every permitted subclass must explicitly extend the sealed class.
Every permitted subclass must define a modifier: final, sealed, or non-sealed.


----------------------------------------------
A statement in an IAM Policy consists of Sid, Effect, Principal, Action, Resource, and Condition. Version is part of the IAM Policy itself, not the statement

{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "CloudWatchEventsBuiltInTargetExecutionAccess",
            "Effect": "Allow",
            "Action": [
                "ec2:RebootInstances",
                "ec2:StopInstances",
                "ec2:TerminateInstances"
            ],
            "Resource": [
                "arn:aws:ec2:eu-west-2:172356682191:instance/i-0810f8c92281c034a"
            ]
        }
    ]
}

----------------S3 bucket---------------------

S3 bucket is nothing but a directly and have unique name across all avialibilty zone, how ever it define within a reason only.
Naming Convention

Bucket names can consist only of lowercase letters, numbers, dots (.), and hyphens (-).
1. No uppercase, No underscore
2. 3-63 character long
3. Not an IP
4. Must start with lowercase letter or number
5. Must Not start with prefix xn---
6. Must Not end with suffix -s3alias

https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html?icmpid=docs_amazons3_console
---------------------------------------


https://www.bairesdev.com/blog/git-github-and-gitlab-whats-the-difference/

------------
https://www.youtube.com/watch?v=9x_6VLk3GtY
------------

LDAP (Lighweight Directory Access Protocol)

Spring Security is a framework to secure your applications
What Spring Security can do

1. Username /Password authentication
2. SSO/Okta/LDAP
3. App level Authorization
4. Microservice Security(Using token/JWT) - allowing to expose certain URL of microservice 
5. Method level security

-- What Is OncePerRequestFilter--
There’s a possibility that the other servlet also has the same filter. In such scenarios, the same filter gets invoked multiple times.

But, we might want to ensure that a specific filter is invoked only once per request. A common use case is when working with Spring Security. When a request goes through the filter chain, we might want some of the authentication actions to happen only once for the request.

--end--

OAuth 2.0 is an authorization framework that enables third-party applications to access protected resources on behalf of a user without requiring the user’s credentials. This is achieved through the use of access tokens, which are issued by an OAuth provider and used by third-party applications to access the user’s resources.

JWT - JSON Web Token (JWT)
JSON - JavaScript Object Notation

------------Spring Application---------------
<dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>
</dependencies>

@RestController
@RequestMapping("/accounts/corporate/savings")
public class AccountsCorporateSavingsEndpoint {

@RestController
@RequestMapping("/accounts/mortgages")
public class AccountsEndpoint {


---Remember------

Server allow access of resource based on JWT token, for each request server response with token having userinformation and Token lifespan

For active session on UI, UI request for refresh token before expiring token on server.


=======================AWS===================================

AWS (Amazon Web Services) is a cloud computing platform provided by Amazon. 
It offerS infrastructure-as-a-service (IaaS), platform-as-a-service (PaaS) and packaged software-as-a-service (SaaS).

Infrastructure as a Service (IaaS) contains the basic building blocks for cloud IT and typically provide access to networking features, computers (virtual or on dedicated hardware), and data storage space. Infrastructure as a Service vendors can help you with the highest level of flexibility and management control over your IT resources and is most similar to existing IT resources that many IT departments and developers are familiar with today.
Infrastructure as a Service (IaaS) is a business model that delivers IT infrastructure like compute, storage, and network resources on a pay-as-you-go basis over the internet.

Platforms as a service (PaaS) vendors remove the need for organizations to manage the underlying infrastructure (usually hardware and operating systems) and this integration allows you to focus on the deployment and management of your applications. This helps you be more efficient as you don’t need to worry about resource procurement, capacity planning, software maintenance, patching, or any of the other undifferentiated heavy lifting involved in running your application.

Software as a Service (SaaS) vendors provide you with software applications that is run and managed by the vendor. In most cases, people referring to Software as a Service are referring to third-party end-user applications. With a SaaS offering you do not have to think about how the service is maintained or how the underlying infrastructure is managed; you only need to think about how you will use that particular piece of software. A common example of a SaaS application is web-based email where you can send and receive email without having to manage feature additions to the email product or maintaining the servers and operating systems that the email program is running